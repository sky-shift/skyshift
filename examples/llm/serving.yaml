kind: Job

metadata: 
  name: llm-serving-job
  labels:
    app: llm-serving

spec:
  replicas: 2
  image: anibali/pytorch:2.0.1-cuda11.8
  resources:
    nvidia.com/gpu: 1
  ports:
    - 28000
  env:
    - name: MODEL_PATH
      value: "mistralai/Mistral-7B-Instruct-v0.2"
    - name: PORT
      value: "28000"
    - name: VLLM_VERSION
      value: "0.2.4"
    - name: PYTHON_VERSION
      value: "311"
  run: |
    # Install vLLM with CUDA 11.8.
    pip3 install https://github.com/vllm-project/vllm/releases/download/v${VLLM_VERSION}/vllm-${VLLM_VERSION}+cu118-cp${PYTHON_VERSION}-cp${PYTHON_VERSION}-manylinux1_x86_64.whl
    pip3 install --upgrade xformers --index-url https://download.pytorch.org/whl/cu118
    python3 -m vllm.entrypoints.openai.api_server --model $MODEL_PATH --port $PORT
  restartPolicy: Always
